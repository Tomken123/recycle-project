import cv2
import numpy as np
from ultralytics import YOLO
import torch
from PIL import Image
import streamlit as st
import os
import torch.serialization
import warnings
from functools import lru_cache
import time
from src.performance_config import get_performance_config, optimize_system
warnings.filterwarnings("ignore")

# å„ªåŒ–ç³»çµ±è¨­ç½®
optimize_system()

class EnhancedRecyclingDetector:
    def __init__(self):
        # ç²å–æ€§èƒ½é…ç½®
        self.config = get_performance_config()
        
        # ä¿®å¾© PyTorch 2.6 æ¨¡å‹è¼‰å…¥å•é¡Œ
        self._setup_torch_compatibility()
        
        # ä½¿ç”¨æ‚¨çš„è‡ªå®šç¾©æ¨¡å‹å’Œé è¨“ç·´æ¨¡å‹
        try:
            # ç²å–æ¨¡å‹é…ç½®
            model_config = self.config.get_model_config()
            
            # å…ˆå˜—è©¦è¼‰å…¥é€šç”¨æ¨¡å‹ï¼ˆé€™å€‹æ‡‰è©²èƒ½æ­£å¸¸å·¥ä½œï¼‰
            self.general_model = YOLO("yolov8n.pt")
            
            # å˜—è©¦è¼‰å…¥è‡ªå®šç¾©æ¨¡å‹
            try:
                self.custom_model = YOLO("yolov8_models/best.pt")
                print("âœ… æ‰€æœ‰æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            except Exception as custom_error:
                print(f"è‡ªå®šç¾©æ¨¡å‹è¼‰å…¥å¤±æ•—: {custom_error}")
                print("å°‡åªä½¿ç”¨é€šç”¨æ¨¡å‹é€²è¡Œæª¢æ¸¬")
                self.custom_model = None
                
        except Exception as e:
            print(f"æ¨¡å‹è¼‰å…¥éŒ¯èª¤: {e}")
            # ä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ
            self.custom_model = None
            self.general_model = None
        
        # å›æ”¶ç‰©é—œéµè©æ˜ å°„ï¼ˆé«˜æº–ç¢ºç‡ç‰ˆï¼‰
        self.recycling_keywords = {
            # å¡‘è† é¡ï¼ˆé«˜ä¿¡å¿ƒåº¦ï¼‰
            "bottle": "å¡‘è† ç“¶",
            "plastic": "å¡‘è† ç“¶", 
            "container": "å¡‘è† å®¹å™¨",
            "bag": "å¡‘è† è¢‹",
            "cup": "å¡‘è† æ¯",
            "straw": "å¸ç®¡",
            "hdpe": "HDPE",    # é«˜å¯†åº¦èšä¹™çƒ¯
            "pet": "PET",        # èšå°è‹¯äºŒç”²é…¸ä¹™äºŒé†‡é…¯
            "pp": "PP",          # èšä¸™çƒ¯
            "ps": "PS",          # èšè‹¯ä¹™çƒ¯
            "pvc": "PVC",        # èšæ°¯ä¹™çƒ¯
            
            # é‡‘å±¬é¡ï¼ˆé«˜ä¿¡å¿ƒåº¦ï¼‰
            "can": "é‡‘å±¬ç½",
            "aluminum": "é‹ç½", 
            "steel": "éµç½",
            "metal": "é‡‘å±¬",
            "wire": "éŠ…ç·š",
            "scrap": "å»¢é‡‘å±¬",
            
            # ç´™é¡ï¼ˆé«˜ä¿¡å¿ƒåº¦ï¼‰
            "paper": "ç´™é¡",
            "cardboard": "ç´™ç®±",
            "newspaper": "å ±ç´™",
            "magazine": "é›œèªŒ",
            "book": "æ›¸ç±",
            "box": "ç´™ç®±",
            
            # ç»ç’ƒé¡ï¼ˆéœ€è¦æ›´æ˜ç¢ºçš„æŒ‡ç¤ºï¼‰
            "glass": "ç»ç’ƒç“¶",
            "jar": "ç»ç’ƒç½",
            "wine": "ç»ç’ƒç“¶",  # é…’ç“¶é€šå¸¸æ˜¯ç»ç’ƒ
            "beer": "ç»ç’ƒç“¶",   # å•¤é…’ç“¶é€šå¸¸æ˜¯ç»ç’ƒ
            
            # é›»å­é¡ï¼ˆé«˜ä¿¡å¿ƒåº¦ï¼‰
            "phone": "é›»å­å»¢æ£„ç‰©",
            "laptop": "é›»å­å»¢æ£„ç‰©", 
            "computer": "é›»å­å»¢æ£„ç‰©",
            "battery": "å»¢é›»æ± ",
            "electronics": "é›»å­å»¢æ£„ç‰©",
            
            # å…¶ä»–ï¼ˆé«˜ä¿¡å¿ƒåº¦ï¼‰
            "tire": "å»¢è¼ªèƒ",
            "wood": "å»¢æœ¨æ",
            "fabric": "å»¢ç´¡ç¹”å“",
            "ceramic": "å»¢é™¶ç“·",
            "oil": "å»¢æ©Ÿæ²¹"
        }
        
        # é«˜ä¿¡å¿ƒåº¦é—œéµè©ï¼ˆåªåŒ¹é…é€™äº›è©æ‰åˆ†é¡ç‚ºå›æ”¶ç‰©ï¼‰
        self.high_confidence_keywords = {
            "bottle", "can", "paper", "glass", "plastic", "metal",
            "cardboard", "newspaper", "book", "phone", "laptop",
            "battery", "tire", "wood", "fabric", "ceramic", "container",
            "box", "jar", "cup", "bag", "wire", "scrap", "wine", "water"
        }
        
        # æ€§èƒ½å„ªåŒ–ï¼šç·©å­˜æª¢æ¸¬çµæœ
        cache_config = self.config.get_cache_config()
        self._detection_cache = {}
        self._cache_size = cache_config['detection_cache_size']
        self._cache_counter = 0
        
    def _setup_torch_compatibility(self):
        """è¨­ç½® PyTorch 2.6 å…¼å®¹æ€§"""
        try:
            import torch.serialization
            from ultralytics.nn.tasks import DetectionModel
            from torch.nn.modules.container import Sequential
            from ultralytics.nn.modules.conv import Conv
            from ultralytics.nn.modules.block import C2f, SPPF
            from ultralytics.nn.modules.head import Detect
            from ultralytics.nn.modules.transformer import TransformerBlock
            from torch.nn.modules.conv import Conv2d
            from torch.nn.modules.batchnorm import BatchNorm2d
            from torch.nn.modules.activation import SiLU
            from torch.nn.modules.container import ModuleList
            from ultralytics.nn.modules.block import Bottleneck, DFL
            from torch.nn.modules.pooling import MaxPool2d
            from torch.nn.modules.upsampling import Upsample
            from ultralytics.nn.modules.conv import Concat
            
            # æ·»åŠ å®‰å…¨çš„å…¨å±€é¡
            torch.serialization.add_safe_globals([
                DetectionModel,
                Sequential,
                Conv,
                Conv2d,
                BatchNorm2d,
                SiLU,
                ModuleList,
                Bottleneck,
                MaxPool2d,
                Upsample,
                Concat,
                DFL,
                C2f,
                SPPF,
                Detect,
                TransformerBlock
            ])
        except Exception as e:
            print(f"PyTorch å…¼å®¹æ€§è¨­ç½®è­¦å‘Š: {e}")
    
    def _clear_cache_if_needed(self):
        """æ ¹æ“šé…ç½®æ¸…ç†ç·©å­˜"""
        cache_config = self.config.get_cache_config()
        self._cache_counter += 1
        
        if self._cache_counter >= cache_config['clear_interval']:
            self._detection_cache.clear()
            self._cache_counter = 0
            print("ğŸ§¹ ç·©å­˜å·²æ¸…ç†")
    
    @lru_cache(maxsize=1000)
    def classify_as_recycling(self, class_name):
        """å°‡é€šç”¨é¡åˆ¥åˆ†é¡ç‚ºå›æ”¶ç‰©é¡åˆ¥ï¼ˆæ”¹é€²ç‰ˆæœ¬ï¼‰"""
        class_name_lower = class_name.lower()
        
        # ç›´æ¥æ˜ å°„å¸¸è¦‹çš„æª¢æ¸¬çµæœ
        direct_mapping = {
            "glass": "ç»ç’ƒç“¶",
            "bottle": "å¡‘è† ç“¶",
            "can": "é‡‘å±¬ç½",
            "box": "ç´™ç®±",
            "paper": "ç´™é¡",
            "plastic": "å¡‘è† ç“¶",
            "metal": "é‡‘å±¬",
            "container": "å¡‘è† å®¹å™¨",
            "jar": "ç»ç’ƒç½",
            "cup": "å¡‘è† æ¯",
            "bag": "å¡‘è† è¢‹"
        }
        
        # é¦–å…ˆæª¢æŸ¥ç›´æ¥æ˜ å°„
        if class_name_lower in direct_mapping:
            return direct_mapping[class_name_lower]
        
        # ç„¶å¾Œæª¢æŸ¥æ˜¯å¦ç‚ºé«˜ä¿¡å¿ƒåº¦é—œéµè©
        for keyword in self.high_confidence_keywords:
            if keyword in class_name_lower:
                # æ‰¾åˆ°é«˜ä¿¡å¿ƒåº¦é—œéµè©ï¼Œè¿”å›å°æ‡‰çš„å›æ”¶ç‰©é¡å‹
                return self.recycling_keywords.get(keyword, keyword)
        
        # é€²è¡Œæ›´å¯¬é¬†çš„åŒ¹é…
        for keyword, recycling_type in self.recycling_keywords.items():
            if keyword in class_name_lower:
                return recycling_type
        
        # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°ï¼Œæª¢æŸ¥æ˜¯å¦åŒ…å«å¸¸è¦‹çš„å›æ”¶ç‰©è©å½™
        common_recycling_words = ["bottle", "can", "box", "paper", "plastic", "glass", "metal"]
        for word in common_recycling_words:
            if word in class_name_lower:
                return self.recycling_keywords.get(word, word)
        
        return None
    
    def detect_with_custom_model(self, image):
        """ä½¿ç”¨ä½ çš„è‡ªå®šç¾©æ¨¡å‹æª¢æ¸¬ï¼ˆ5é¡ï¼‰- å„ªåŒ–ç‰ˆ"""
        if self.custom_model is None:
            return []
        
        try:
            start_time = time.time()
            
            # ä½¿ç”¨æ€§èƒ½é…ç½®
            model_config = self.config.get_model_config()
            results = self.custom_model(
                image, 
                verbose=model_config['verbose'],
                conf=model_config['conf'],
                iou=model_config['iou'],
                device=model_config['device']
            )
            
            detection_time = time.time() - start_time
            
            detections = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        bbox = box.xyxy[0].cpu().numpy()
                        confidence = float(box.conf[0])
                        class_id = int(box.cls[0])
                        class_name = result.names[class_id]
                        
                        # æª¢æŸ¥æ˜¯å¦ç‚ºå›æ”¶ç‰©
                        recycling_type = self.classify_as_recycling(class_name)
                        if recycling_type:
                            detections.append({
                                'bbox': bbox.tolist(),
                                'class_name': recycling_type,
                                'confidence': confidence,
                                'source': 'custom_model'
                            })
                        else:
                            detections.append({
                                'bbox': bbox.tolist(),
                                'class_name': class_name,
                                'confidence': confidence,
                                'source': 'custom_model'
                            })
            
            print(f"è‡ªå®šç¾©æ¨¡å‹æª¢æ¸¬å®Œæˆï¼Œè€—æ™‚: {detection_time:.3f}ç§’")
            return detections
            
        except Exception as e:
            print(f"è‡ªå®šç¾©æ¨¡å‹æª¢æ¸¬éŒ¯èª¤: {e}")
            return []
    
    def detect_with_general_model(self, image):
        """ä½¿ç”¨é€šç”¨æ¨¡å‹æª¢æ¸¬ - å„ªåŒ–ç‰ˆ"""
        if self.general_model is None:
            return []
        
        try:
            start_time = time.time()
            
            # ä½¿ç”¨è¼ƒä½çš„ä¿¡å¿ƒåº¦é–¾å€¼ä»¥ç¢ºä¿æª¢æ¸¬åˆ°ç‰©é«”ï¼Œä½†å¾ŒçºŒæœƒéæ¿¾
            model_config = self.config.get_model_config()
            detection_conf = 0.3  # é™ä½æª¢æ¸¬ä¿¡å¿ƒåº¦ä»¥ç¢ºä¿èƒ½æª¢æ¸¬åˆ°ç‰©é«”
            
            results = self.general_model(
                image, 
                verbose=model_config['verbose'],
                conf=detection_conf,  # ä½¿ç”¨è¼ƒä½çš„ä¿¡å¿ƒåº¦é€²è¡Œæª¢æ¸¬
                iou=model_config['iou'],
                device=model_config['device']
            )
            
            detection_time = time.time() - start_time
            
            detections = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        bbox = box.xyxy[0].cpu().numpy()
                        confidence = float(box.conf[0])
                        class_id = int(box.cls[0])
                        class_name = result.names[class_id]
                        
                        # è™•ç†æ‰€æœ‰æª¢æ¸¬åˆ°çš„ç‰©é«”
                        if confidence >= 0.3:  # é™ä½ä¿¡å¿ƒåº¦è¦æ±‚
                            # æª¢æŸ¥æ˜¯å¦ç‚ºå›æ”¶ç‰©
                            recycling_type = self.classify_as_recycling(class_name)
                            if recycling_type:
                                detections.append({
                                    'bbox': bbox.tolist(),
                                    'class_name': recycling_type,
                                    'confidence': confidence,
                                    'source': 'general_model'
                                })
                            else:
                                # å¦‚æœæ²’æœ‰åˆ†é¡ç‚ºå›æ”¶ç‰©ï¼Œä½†ä¿¡å¿ƒåº¦è¼ƒé«˜ï¼Œä¹Ÿè¨˜éŒ„ä¸‹ä¾†
                                if confidence >= 0.5:
                                    detections.append({
                                        'bbox': bbox.tolist(),
                                        'class_name': class_name,
                                        'confidence': confidence,
                                        'source': 'general_model'
                                    })
            
            print(f"é€šç”¨æ¨¡å‹æª¢æ¸¬å®Œæˆï¼Œè€—æ™‚: {detection_time:.3f}ç§’ï¼Œæª¢æ¸¬åˆ° {len(detections)} å€‹å›æ”¶ç‰©")
            return detections
            
        except Exception as e:
            print(f"é€šç”¨æ¨¡å‹æª¢æ¸¬éŒ¯èª¤: {e}")
            return []
    
    def fast_check_overlap(self, bbox1, bbox2, threshold=None):
        """å¿«é€Ÿé‡ç–Šæª¢æŸ¥ï¼ˆå„ªåŒ–ç‰ˆï¼‰"""
        if threshold is None:
            threshold = self.config.OVERLAP_THRESHOLD
            
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        # å¿«é€Ÿé‚Šç•Œæª¢æŸ¥
        if x2_1 < x1_2 or x2_2 < x1_1 or y2_1 < y1_2 or y2_2 < y1_1:
            return False
        
        # è¨ˆç®—äº¤é›†
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / union > threshold
    
    def combine_detections_fast(self, custom_detections, general_detections):
        """å¿«é€Ÿåˆä½µæª¢æ¸¬çµæœï¼ˆå„ªåŒ–ç‰ˆï¼‰"""
        combined = custom_detections.copy()
        
        # å‰µå»ºè‡ªå®šç¾©æª¢æ¸¬çš„é‚Šç•Œæ¡†ç´¢å¼•
        custom_bboxes = [det['bbox'] for det in custom_detections]
        
        # å¿«é€Ÿéæ¿¾é€šç”¨æª¢æ¸¬
        for general_detection in general_detections:
            is_duplicate = False
            
            # åªæª¢æŸ¥èˆ‡è‡ªå®šç¾©æª¢æ¸¬çš„é‡ç–Š
            for custom_bbox in custom_bboxes:
                if self.fast_check_overlap(general_detection['bbox'], custom_bbox):
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                combined.append(general_detection)
        
        return combined
    
    def detect_recycling_objects(self, image):
        """ä¸»è¦æª¢æ¸¬å‡½æ•¸ï¼ˆé«˜æ€§èƒ½ç‰ˆæœ¬ï¼‰"""
        start_time = time.time()
        
        # æª¢æŸ¥ç·©å­˜
        if self.config.ENABLE_CACHE:
            image_hash = hash(str(image.shape) + str(image.dtype))
            if image_hash in self._detection_cache:
                print("ä½¿ç”¨ç·©å­˜çµæœ")
                return self._detection_cache[image_hash]
        
        # æª¢æ¸¬ï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰
        custom_detections = []
        general_detections = []
        
        # å„ªå…ˆä½¿ç”¨é€šç”¨æ¨¡å‹ï¼ˆæ›´å¿«ï¼‰
        if self.general_model is not None:
            general_detections = self.detect_with_general_model(image)
            
            # å¦‚æœé€šç”¨æ¨¡å‹æª¢æ¸¬åˆ°è¶³å¤ çš„ç‰©é«”ï¼Œå°±ä¸ä½¿ç”¨è‡ªå®šç¾©æ¨¡å‹
            if len(general_detections) >= 2:
                final_detections = general_detections
            else:
                # å¦‚æœé€šç”¨æ¨¡å‹æª¢æ¸¬çµæœä¸è¶³ï¼Œå˜—è©¦è‡ªå®šç¾©æ¨¡å‹
                if self.custom_model is not None:
                    custom_detections = self.detect_with_custom_model(image)
                    # åˆä½µçµæœ
                    combined_detections = self.combine_detections_fast(custom_detections, general_detections)
                    
                    # å¿«é€Ÿå»é‡
                    final_detections = []
                    seen_combinations = set()
                    
                    for detection in combined_detections:
                        # å‰µå»ºå”¯ä¸€æ¨™è­˜ç¬¦
                        bbox_key = tuple(round(x, 2) for x in detection['bbox'])
                        class_key = detection['class_name']
                        combination = (bbox_key, class_key)
                        
                        if combination not in seen_combinations:
                            seen_combinations.add(combination)
                            final_detections.append(detection)
                else:
                    final_detections = general_detections
        else:
            # åªæœ‰è‡ªå®šç¾©æ¨¡å‹å¯ç”¨
            if self.custom_model is not None:
                final_detections = self.detect_with_custom_model(image)
            else:
                final_detections = []
        
        # ç·©å­˜çµæœ
        if self.config.ENABLE_CACHE and len(self._detection_cache) < self._cache_size:
            self._detection_cache[image_hash] = final_detections
        
        # æ¸…ç†ç·©å­˜
        self._clear_cache_if_needed()
        
        total_time = time.time() - start_time
        print(f"ç¸½æª¢æ¸¬æ™‚é–“: {total_time:.3f}ç§’")
        
        return final_detections

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    detector = EnhancedRecyclingDetector()
    
    # æ¸¬è©¦åœ–ç‰‡
    test_image = "test_image.jpg"
    if os.path.exists(test_image):
        image = cv2.imread(test_image)
        detections = detector.detect_recycling_objects(image)
        
        print(f"æª¢æ¸¬åˆ° {len(detections)} å€‹å›æ”¶ç‰©:")
        for detection in detections:
            print(f"- {detection['class_name']} (ä¿¡å¿ƒåº¦: {detection['confidence']:.2f})") 